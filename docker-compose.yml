services:
  # Application Service
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: portfolio-blog-api
    read_only: true
    tmpfs:
      - /tmp:size=256M
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    # ports:  # API served via nginx reverse proxy
    #   - "8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      # Database Configuration
      - DATABASE_URL=r2dbc:postgresql://postgres:5432/blog
      - DATABASE_USERNAME=${DB_USERNAME:-postgres}
      - DATABASE_PASSWORD=${DB_PASSWORD:-postgres}
      # Redis Configuration
      - SPRING_DATA_REDIS_HOST=redis
      - SPRING_DATA_REDIS_PORT=6379
      - SPRING_DATA_REDIS_PASSWORD=${REDIS_PASSWORD:-redis}
      # Security - REQUIRED: Set these in .env file or environment
      - JWT_SECRET=${JWT_SECRET:?JWT_SECRET is required}
      # Admin User (optional - for initial setup)
      - ADMIN_EMAIL=${ADMIN_EMAIL:-}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-}
      - ADMIN_NAME=${ADMIN_NAME:-Administrator}
      # CORS Configuration
      - CORS_ALLOWED_ORIGINS=${CORS_ALLOWED_ORIGINS:-http://localhost:3000,http://127.0.0.1:3000}
      # INC-12/SEC-06: reCAPTCHA v3 — F-402: secrets must come from .env file
      - RECAPTCHA_ENABLED=${RECAPTCHA_ENABLED:-true}
      - RECAPTCHA_SITE_KEY=${RECAPTCHA_SITE_KEY:?RECAPTCHA_SITE_KEY is required}
      - RECAPTCHA_SECRET_KEY=${RECAPTCHA_SECRET_KEY:?RECAPTCHA_SECRET_KEY is required}
      - RECAPTCHA_SCORE_THRESHOLD=${RECAPTCHA_SCORE_THRESHOLD:-0.5}
      # HashiCorp Vault (C1 — secrets management)
      - VAULT_ADDR=${VAULT_ADDR:-http://192.168.1.193:30820}
      - VAULT_ROLE_ID=${VAULT_ROLE_ID}
      - VAULT_SECRET_ID=${VAULT_SECRET_ID}
      # ── Datadog APM (agent runs as sidecar) ──
      - DD_AGENT_ENABLED=${DD_AGENT_ENABLED:-true}
      - DD_AGENT_HOST=datadog-agent
      - DD_TRACE_AGENT_URL=http://datadog-agent:8126
      - DD_SERVICE=portfolio-blog-api
      - DD_ENV=development
      - DD_VERSION=2.0.0
      - DD_LOGS_INJECTION=true
      - DD_PROFILING_ENABLED=false
      - DD_METRICS_ENABLED=true
      # ── Media Storage ──
      - STORAGE_TYPE=${STORAGE_TYPE:-local}
      - S3_ENDPOINT=${S3_ENDPOINT:-http://minio:9000}
      - S3_REGION=${S3_REGION:-us-east-1}
      - S3_BUCKET=${S3_BUCKET:-media}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY:-minioadmin}
      - S3_SECRET_KEY=${S3_SECRET_KEY:-minioadmin}
      - S3_PUBLIC_URL=${S3_PUBLIC_URL:-http://localhost:9000/media}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    volumes:
      - uploads_data:/app/uploads
      - app_logs:/app/logs
    networks:
      - blog-frontend-network
      - blog-backend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"java","service":"portfolio-blog-api"}]'

  # PostgreSQL Database
  postgres:
    image: postgres:17-alpine
    container_name: blog-postgres
    # ports:
    #   - "5432:5432"  # Uncomment for local development access
    environment:
      POSTGRES_DB: blog
      POSTGRES_USER: ${DB_USERNAME:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-postgres}
      # DB-06: Explicitly set UTF-8 encoding for multi-language support
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8"
      LANG: en_US.UTF-8
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./src/main/resources/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d blog"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - blog-backend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"postgresql","service":"blog-postgres"}]'

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: blog-redis
    # ports:
    #   - "6379:6379"  # Uncomment for local development access
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD:-redis}
    read_only: true
    tmpfs:
      - /tmp:size=64M
    environment:
      REDISCLI_AUTH: ${REDIS_PASSWORD:-redis}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - blog-backend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"redis","service":"blog-redis"}]'

  # MinIO — S3-compatible object storage (local dev CDN alternative)
  minio:
    image: minio/minio:latest
    container_name: blog-minio
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # Web console
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY:-minioadmin}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY:-minioadmin}
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 15s
      timeout: 5s
      retries: 5
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - blog-backend-network
    restart: unless-stopped
    profiles:
      - s3

  # Prometheus (Metrics) — INFRA-04: Access via nginx reverse proxy only
  prometheus:
    image: prom/prometheus:latest
    container_name: blog-prometheus
    # ports:  # INFRA-04: Prometheus NOT exposed directly; access via nginx at /prometheus
    #   - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/bearer_token:/etc/prometheus/bearer_token:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.external-url=/prometheus'
      - '--web.route-prefix=/prometheus'
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 512M
    networks:
      - blog-backend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"prometheus","service":"blog-prometheus"}]'

  # Grafana (Dashboards)
  # SEC-06: Removed direct port exposure; access via nginx reverse proxy
  grafana:
    image: grafana/grafana:latest
    container_name: blog-grafana
    # ports:  # SEC-06: Grafana NOT exposed directly; access via nginx at /grafana
    #   - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      # INFRA-04: Generate a secure password with: openssl rand -base64 32
      # Add GRAFANA_PASSWORD=<generated_password> to your .env file
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:?GRAFANA_PASSWORD is required - set a strong password (generate with: openssl rand -base64 32)}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 256M
    networks:
      - blog-backend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"grafana","service":"blog-grafana"}]'

  # Frontend (Angular)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: portfolio-blog-frontend
    read_only: true
    tmpfs:
      - /tmp:size=64M
      - /var/cache/nginx:size=64M
      - /var/run:size=1M
    # ports:  # Served via nginx
    #   - "4000:4000"
    depends_on:
      app:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:4000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 256M
    networks:
      - blog-frontend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"nginx","service":"portfolio-blog-frontend"}]'

  # INFRA-03: Nginx Reverse Proxy — SSL/TLS termination, serves frontend,
  # proxies API and Prometheus with basic auth
  nginx:
    image: nginx:alpine
    container_name: blog-nginx
    read_only: true
    tmpfs:
      - /tmp:size=64M
      - /var/cache/nginx:size=128M
      - /var/run:size=1M
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/.htpasswd:/etc/nginx/.htpasswd:ro
      # Uncomment and mount your SSL certs for production:
      # - ./nginx/certs:/etc/nginx/certs:ro
    depends_on:
      - app
      - frontend
      - prometheus
      - grafana
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "5"
    deploy:
      resources:
        limits:
          memory: 256M
    networks:
      - blog-frontend-network
      - blog-backend-network
    restart: unless-stopped
    labels:
      com.datadoghq.ad.logs: '[{"source":"nginx","service":"blog-nginx"}]'

  # ── Datadog Agent (APM + log collection + infrastructure metrics) ──
  datadog-agent:
    image: gcr.io/datadoghq/agent:7
    container_name: datadog-agent
    pid: host
    environment:
      - DD_API_KEY=${DD_API_KEY}
      - DD_SITE=${DD_SITE:-us5.datadoghq.com}
      - DD_APM_ENABLED=true
      - DD_APM_NON_LOCAL_TRAFFIC=true
      - DD_LOGS_ENABLED=true
      - DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL=true
      - DD_CONTAINER_EXCLUDE="name:datadog-agent"
      - DD_DOGSTATSD_NON_LOCAL_TRAFFIC=true
      - DD_PROCESS_AGENT_ENABLED=true
      - DD_TAGS=env:development,service:portfolio-blog,team:catananti
      - DD_HOSTNAME=dev-localhost
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc/:/host/proc/:ro
      - /sys/fs/cgroup:/host/sys/fs/cgroup:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    networks:
      - blog-backend-network
      - blog-frontend-network
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"
    deploy:
      resources:
        limits:
          memory: 512M

networks:
  blog-frontend-network:
    driver: bridge
  blog-backend-network:
    driver: bridge
    internal: true

volumes:
  postgres_data:
  redis_data:
  minio_data:
  prometheus_data:
  grafana_data:
  uploads_data:
  app_logs:
